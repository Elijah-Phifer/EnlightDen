# -*- coding: utf-8 -*-
"""
MindMap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VyWxfM6oMbyG6Pk5v1BCroxLnBgbM7zz
"""


!pip install openai
!pip install networkx matplotlib
!pip install pdfminer.six

from openai import OpenAI
import os
import matplotlib.pyplot as plt
import networkx as nx
import json

client = OpenAI(
  api_key='',
)

from pdfminer.high_level import extract_text


def extract_text_from_pdf(pdf_path):
    return extract_text(pdf_path)

def convert_to_markdown(text):
    lines = text.split("\\\\n")
    for i, line in enumerate(lines):
        stripped = line.strip()
        if stripped.isupper() and len(stripped) < 50:
            lines[i] = f"## {stripped}"
    return "\\\\n".join(lines)

def process_pdfs_in_directory(pdf_directory): # markdown_directory
    for filename in os.listdir(pdf_directory):
        if filename.endswith(".pdf"):
            ...
            # [The rest of the code to process each PDF]
            # markdown_filename = filename.replace(".pdf", "_markdown.md")
            # markdown_path = os.path.join(markdown_directory, markdown_filename)

            # Check if the markdown file already exists
            # if os.path.exists(markdown_path):
            #     print(f"Markdown for {filename} already exists. Skipping...")
            #     continue

            pdf_path = os.path.join(pdf_directory, filename)

            # Extract text from PDF
            extracted_text = extract_text_from_pdf(pdf_path)

            # Convert extracted text to markdown
            markdown_text = convert_to_markdown(extracted_text)

            return markdown_text

            # # Save the markdown text
            # with open(markdown_path, "w") as md_file:
            #     md_file.write(markdown_text)
            # print(f"Processed {filename} and saved Markdown to {markdown_filename}")

pdf_directory = "/content/PDFS"
# markdown_directory = "path_to_save_markdown_files"
notes = process_pdfs_in_directory(pdf_directory)

format = """
{
  "title": "Title of Notes or overall subject of notes",
  "main_topics": [
    {
      "name": "Name of first main topic",
      "subtopics": ["Subtopic One", "Subtopic Two", "Subtopic Three", "Subtopic Four", "Subtopic Five", ..., "subtopics that extend beyond the notes", ...]
    },
    {
      "name": "Name of second main topic",
      "subtopics": ["Subtopic One", "Subtopic Two", "Subtopic Three", "Subtopic Four", "Subtopic Five", ..., "subtopics that extend beyond the notes", ...]
    },
    ...,
    {
      "name": "more topics that extended beyond the notes",
      "subtopics": ...
    },
    ...
  ]
}
"""

graph_prompt = f"""

Take the following notes and extrapolate them into a JSON text (format it like this: {format})
that can be converted into a bubble map / mind map  (Fill in any gaps in knowledge in the notes as necessary in the bubble map.
Also add information that would extend knowledge beyond the notes in the bubble map):

{notes}

"""
# print(graph_prompt)

response = client.chat.completions.create(
  model="gpt-3.5-turbo-0125",#-3.5-turbo-0125
  response_format={ "type": "json_object" },
  messages=[
    {"role": "system", "content": "You are a helpful assistant designed to output JSON"},
    {"role": "user", "content": f"{graph_prompt}"}
  ]
)
# print(response.choices[0].message.content)

JSON_data = str(response.choices[0].message.content)


# The JSON data provided

JSON_data_dict = json.loads(JSON_data)


def build_graph(data):
    G = nx.Graph()
    root = data['title']
    G.add_node(root, size=20, color='lightblue')

    for topic in data['main_topics']:
        G.add_node(topic['name'], size=15, color='lightgreen')
        G.add_edge(root, topic['name'], weight=2)

        for subtopic in topic['subtopics']:
            subtopic_name = f"{topic['name']}: {subtopic}"
            G.add_node(subtopic_name, size=10, color='lightgrey')
            G.add_edge(topic['name'], subtopic_name, weight=1)

    return G

G = build_graph(JSON_data_dict)

# Specify node positions using the spring layout
pos = nx.spring_layout(G, k=0.15, iterations=20)

# Draw the graph
plt.figure(figsize=(12, 12))
nx.draw(G, pos, with_labels=True, node_size=[G.nodes[node]['size']*100 for node in G.nodes],
        node_color=[G.nodes[node]['color'] for node in G.nodes],
        font_size=8, edge_color='gray')

plt.title(JSON_data_dict['title'])
plt.show()

format2 = """
{
  "title": "Title of Notes or overall subject of notes",
  "main_topics": [
    {
      "name": "Name of first main topic",
      "summary": "{informational summary of first main topic}",
      "subtopics": ["Subtopic One", "Subtopic Two", "Subtopic Three", "Subtopic Four", "Subtopic Five",..., "topics that extend beyond the notes", ...],
      "summary_of_subtopics": [
          "{informational summary of Subtopic One}",
          "{informational summary of Subtopic Two}",
          "{informational summary of Subtopic Three}",
          "{informational summary of Subtopic Four}",
          "{informational summary of Subtopic Five}",
          ...,
          "{information that extends beyond the notes}",
          ...
          ]
    },
    {
      "name": "Name of second main topic",
      "summary": "{informational summary of second main topic}",
      "subtopics": ["Subtopic One", "Subtopic Two", "Subtopic Three", "Subtopic Four", "Subtopic Five",..., "topics that extend beyond the notes", ...],
      "summary_of_subtopics": [
          "{informational summary of Subtopic One}",
          "{informational summary of Subtopic Two}",
          "{informational summary of Subtopic Three}",
          "{informational summary of Subtopic Four}",
          "{informational summary of Subtopic Five}",
          ...
          "{information that extends beyond the notes}",
          ...
          ]
    }
  ]
}
"""

prompt = ("If you are not given notes or text for reference, proceed with the following " +
f"instructions by writing original and reliable information where necessary. Take this JSON information ({JSON_data}) and make another JSON code/text in the following form filling in " +
f"the necessary information: {format2}")

# print(prompt)

response = client.chat.completions.create(
  model="gpt-3.5-turbo-0125",
  response_format={ "type": "json_object" },
  messages=[
    {"role": "system", "content": "You are a helpful assistant designed to output JSON"},
    {"role": "user", "content": f"use the following text ({notes}) to carry out the following prompt: {prompt}"}
  ]
)
# print(response.choices[0].message.content)

JSON_data1 = str(response.choices[0].message.content)

JSON_data_dict1 = json.loads(JSON_data1)

form = """

"test_title": "Title of Test",
  "questions": [
    {
      "question": "Question based off of the notes",
      "options": ["option A", "option B", "option C", ...],
      "correct_answer": "the correct answer",
      "topic": "topic this quesion was baed off of"
    },
    {
      "question": "Question based off of the notes",
      "options": ["option A", "option B", "option C", ...],
      "correct_answer": "the correct answer",
      "topic": "topic this quesion was baed off of"
    },
    ...

"""

prompt2 = f"""

make a test put into this JSON format({form}) that is based off of this JSON information (make sure the test is atleast 5 questions long):

{JSON_data1}

"""

# print(prompt2)

results = {"correct": [], "wrong": []}  # Initialize a dictionary to store results
def generate_test(prompt):
  response = client.chat.completions.create(
  model="gpt-3.5-turbo-0125",
  response_format={ "type": "json_object" },
  messages=[
    {"role": "system", "content": "You are a helpful assistant designed to output JSON"},
    {"role": "user", "content": f"Carry out the following prompt: {prompt2}"}
  ]
  )
  #print(response.choices[0].message.content)

  JSON_data2 = str(response.choices[0].message.content)

  JSON_data_dict2 = json.loads(JSON_data2)

  return JSON_data_dict2

def administer_test(test_data):
    score = 0
    total_questions = len(test_data["questions"])

    print(f"Test: {test_data['test_title']}\n")

    for i, question in enumerate(test_data["questions"], start=1):
        print(f"Question {i}: {question['question']}")
        for j, option in enumerate(question["options"], start=1):
            print(f"{j}. {option}")
        user_answer = input("Your answer (number): ")

        try:
            user_answer = int(user_answer)
            if 1 <= user_answer <= len(question["options"]) and question["options"][user_answer-1] == question["correct_answer"]:
                print("Correct!\n")
                score += 1
                results["correct"].append(question["question"])
            else:
                print(f"Wrong! The correct answer was: {question['correct_answer']}\n")
                results["wrong"].append(question["question"])
        except ValueError:
            print("Invalid answer. Please enter a number.\n")

    print(f"Your score is {score}/{total_questions}.")

    print(f"Your test results have been saved. {results}")
    return results

def generate_improved_test(jsonData, results):
  json_results = json.dumps(results, indent=4)
  prompt3 = f"""

  Take the following JSON data ({str(jsonData)})
  and the following results from a previous examination based on the JSON data ({str(json_results)})
  and make an improved examination in the following form ({form}) that tests what the user got wrong on the previous test.
  make sure you ask the questions in new ways and include questions that could be helpful to make the user think and learn.
  Also make sure the test is at least five questions long. Make it longer if need be.

  """


  response = client.chat.completions.create(
  model="gpt-3.5-turbo-0125",
  response_format={ "type": "json_object" },
  messages=[
    {"role": "system", "content": "You are a helpful assistant designed to output JSON"},
    {"role": "user", "content": f"Carry out the following prompt: {prompt3}"}
  ]
  )
  #print(response.choices[0].message.content)

  JSON_data3 = str(response.choices[0].message.content)

  JSON_data_dict3 = json.loads(JSON_data3)

  return JSON_data_dict3

#Creating and administering a test and improving based on results
def test_knowledge():
  attempts = 0
  while(True):
    question = input("Do you want to take a test on your notes?(Y/N): ")
    testing = (question.lower() == "y")
    if(not testing):
      print(f"cool bro. BYE. you've taken the test {attempts} times")
      break
    else:
      if(attempts == 0):
        attempts = attempts + 1
        test_data = generate_test(JSON_data1)
        results = administer_test(test_data)
      if(attempts > 0):
        attempts = attempts + 1
        test_data = generate_improved_test(JSON_data1, results)
        results = administer_test(test_data)


test_knowledge()

q = """
Welcome to EnlightDen, your personal study tool!

Let's start out with a quick recall exercise. Pick a recall exercise:
1. Brain Dumping
2. Short Essay topic
3. Mind Mapping (organized brain dump)
4. Prompted Mind Mapping (organized brain dump with a prompt)
5. Take a practice test

Answer
"""


def brain_dump():
  print("\n" + f"Brain dump all you know about {JSON_data_dict['title']} \n")
  print("Please write your brain dump below. Type 'END' on a new line when you are finished.\n")

  lines = []
  while True:
      line = input()
      if line.strip().upper() == 'END':
          break
      lines.append(line)

  dump = "\n".join(lines)

  print(dump)

  response = client.chat.completions.create(
  model="gpt-3.5-turbo-0125",
  response_format={ "type": "json_object" },
  messages=[
    {"role": "system", "content": "You are a helpful assistant designed to output JSON"},
    {"role": "user", "content": f"Carry out the following prompt: {prompt2}"}
  ]
  )
  #print(response.choices[0].message.content)

  JSON_data2 = str(response.choices[0].message.content)

  JSON_data_dict2 = json.loads(JSON_data2)

  return JSON_data_dict2

def short_essay():
  x=1

def mind_mapping():
  x=1

def PRMT_mind_mapping():
  x=1

def practice_test():
  x=1

while True:
  decision = input(q)
  match decision:
    case "1": brain_dump()
    case "2": print("2")
    case "3": print("3")
    case "4": print("4")
    case "5": print("5")
    case _:
      print("alright bye dude");
      break

